{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/krtucho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#Given an object named 'texts' (a list of tokenized texts, ie a list of lists of tokens)\n",
    "#from gensim.test.utils import common_texts as texts\n",
    "\n",
    "# Create a corpus from a list of lists of tokens\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "texts=[]\n",
    "file = open(\"TokenVieuxN.txt\", \"r\")\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "#print(stopwords.words())\n",
    "\n",
    "for line in lines:\n",
    "  line=line.strip()\n",
    "  lt=line.split(\",\")\n",
    "#Potential ill-character cleaning\n",
    "  for i in range(len(lt)):\n",
    "    lt[i]=lt[i].replace('[','')\n",
    "    lt[i]=lt[i].replace(']','')\n",
    "    lt[i]=lt[i].replace('\"','')\n",
    "    lt[i]=lt[i].replace('\\n','')\n",
    "    lt[i]=lt[i].replace(' ', '')\n",
    "#End : Potential ill-characters cleaning\n",
    "# print(lt)\n",
    "  ltc=[word for word in lt if not word in stopwords.words()] # Remove Stopwords activated\n",
    "#  print(\"C\", ltc)\n",
    "  texts.append(lt)\n",
    "\n",
    "#for text in texts:\n",
    "  #print(text)\n",
    "\n",
    "#Here set the number of topics(to be changed if necessary)\n",
    "nb=10\n",
    "  \n",
    "id2word = Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "#print(corpus)\n",
    "\n",
    "# Print dictionnary # ***********\n",
    "# for i in id2word:\n",
    "#   print(i, id2word[i])\n",
    "\n",
    "# Train the lda model on the corpus.\n",
    "from gensim.models import LdaModel\n",
    "lda = LdaModel(corpus, num_topics=nb)\n",
    "\n",
    "# Print topic descrition\n",
    "for i in range(0, nb-1):\n",
    "  value=lda.get_topic_terms(i)\n",
    "#  print(value)\n",
    "  # print(\"Topic \", i) # *******************\n",
    "  # for j in value:\n",
    "  #   print(id2word[j[0]], \" - P=\", j[1])\n",
    "  # print() # *******************\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('Coherence= ', coherence_lda) # *******************************\n",
    "\n",
    "# from gensim.utils import simple_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x7f7278acc0f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = lda.get_document_topics(corpus)\n",
    "# doc_topic = []\n",
    "# for topic in doc_topics:\n",
    "#     for item in topic:\n",
    "#         doc_topic.append(item)\n",
    "\n",
    "# # doc_topics = [inside_doc_topic for inside_doc_topic in [doc_topic for doc_topic in doc_topics]]\n",
    "\n",
    "doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typical Document for each topic, topic proportion (or probability) in documents\n",
      "Topic 5: 1 :  \n",
      "with prob: 0.994229793548584\n",
      "\n",
      "Topic 2: 3 :  \n",
      "with prob: 0.9962176084518433\n",
      "\n",
      "Topic 8: 5 :  \n",
      "with prob: 0.9965642094612122\n",
      "\n",
      "Topic 7: 6 :  \n",
      "with prob: 0.9959448575973511\n",
      "\n",
      "Topic 9: 8 :  \n",
      "with prob: 0.9937487244606018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the topic distribution for each document\n",
    "\n",
    "most_typical_docs = {}\n",
    "for i, doc_topic in enumerate(doc_topics):\n",
    "    for item in doc_topic: \n",
    "        topic, prob = item\n",
    "        if most_typical_docs.__contains__(topic):\n",
    "            if most_typical_docs[topic][1] < prob:\n",
    "                most_typical_docs[topic] = (topic, prob, i)\n",
    "        else:\n",
    "            most_typical_docs[topic] = (topic, prob, i)\n",
    "        \n",
    "print(\"Typical Document for each topic, topic proportion (or probability) in documents\") \n",
    "for i, prob, doc in most_typical_docs.values():\n",
    "    print(f\"Topic {i}: {doc} :  \\nwith prob: {prob}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typical Document for each topic, cosine_similarity\n",
      "Topic 0: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 1: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 2: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 3: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 4: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 5: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 6: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 7: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 8: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n",
      "Topic 9: ['abstract', 'the', 'accumulation', 'of', 'nonenzymatic', 'modifications', 'on', 'both', 'dna', 'and', 'protein', 'molecules', 'under', 'the', 'attack', 'of', 'reactive', 'oxygen', 'species', 'ros', 'is', 'one', 'of', 'the', 'most', 'possible', 'factors', 'responsible', 'for', 'the', 'functional', 'deterioration', 'in', 'aged', 'cells', 'direct', 'protein', 'modifications', 'as', 'well', 'as', 'dna', 'damages', 'may', 'be', 'detectable', 'in', 'part', 'by', 'proteome', 'analysis', 'if', 'the', 'gene', 'expression', 'is', 'affected', 'by', 'the', 'damages', 'on', 'dna', 'the', 'novel', 'term', '“proteome”', 'which', 'is', 'a', 'compound', 'of', '“protein”', 'and', '“genome”', 'means', 'a', 'whole', 'set', 'of', 'proteins', 'expressed', 'in', 'a', 'tissue', 'or', 'a', 'cell', 'strain', 'to', 'be', 'investigated', 'proteomics', 'is', 'a', 'methodology', 'for', 'analyzing', 'proteomes', 'in', 'proteomics', 'twodimensional', 'gel', 'electrophoresis', 'is', 'performed', 'primarily', 'to', 'separate', 'constitutive', 'proteins', 'followed', 'by', 'mass', 'spectrometry', 'to', 'identify', 'each', 'protein', 'of', 'interest', 'and', 'to', 'determine', 'a', 'possible', 'posttranslational', 'modification', 'proteomics', 'has', 'offered', 'us', 'an', 'innovative', 'tool', 'for', 'investigating', 'the', 'molecular', 'mechanisms', 'of', 'cellular', 'aging']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the topic distribution for each document\n",
    "doc_topics = lda.get_document_topics(corpus)\n",
    "\n",
    "# print(doc_topics)\n",
    "# doc_topics\n",
    "# for doc_topic in doc_topics:\n",
    "#     print(doc_topic)\n",
    "\n",
    "# Get the most typical document for each topic based on cosine similarity\n",
    "topic_words = [lda.get_topic_terms(i, topn=10) for i in range(nb)]\n",
    "doc_vectors = np.zeros((len(texts), nb))\n",
    "for i, doc in enumerate(texts):\n",
    "    doc_term_vec = id2word.doc2bow(doc)\n",
    "    for j, prob in lda[doc_term_vec]:\n",
    "        doc_vectors[i][j] = prob\n",
    "        # print(\"Prob: \", prob)\n",
    "\n",
    "\n",
    "\n",
    "most_typical_docs = []\n",
    "for topic in range(nb):\n",
    "    topic_vec = np.zeros((1, nb))\n",
    "    for word, _ in topic_words[topic]:\n",
    "        if word in id2word.token2id:\n",
    "            topic_vec[0][lda.get_term_topics(word)[0][0]] = 1\n",
    "    similarity_scores = cosine_similarity(doc_vectors, topic_vec)\n",
    "    # print(\"sim Scores: \", similarity_scores)\n",
    "    most_typical_doc_index = np.argmax(similarity_scores)\n",
    "    # print(\"topic: \", topic, \"mtdi: \", most_typical_doc_index)\n",
    "    most_typical_docs.append(texts[most_typical_doc_index])\n",
    "\n",
    "# Print the most typical document for each topic\n",
    "print(\"Typical Document for each topic, cosine_similarity\") \n",
    "for i, doc in enumerate(most_typical_docs):\n",
    "    print(f\"Topic {i}: {doc}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  0 :  ['the', 'of', 'and', 'in', 'to', 'index', 'neurons', 'has', 'used', 'for']\n",
      "Doc 0 and Topic 0 cosine similarity is 1\n",
      "Doc 1 and Topic 0 cosine similarity is 1\n",
      "Doc 2 and Topic 0 cosine similarity is 1\n",
      "Doc 3 and Topic 0 cosine similarity is 1\n",
      "Doc 4 and Topic 0 cosine similarity is 1\n",
      "Doc 5 and Topic 0 cosine similarity is 1\n",
      "Doc 6 and Topic 0 cosine similarity is 1\n",
      "Doc 7 and Topic 0 cosine similarity is 1\n",
      "Doc 8 and Topic 0 cosine similarity is 1\n",
      "Doc 9 and Topic 0 cosine similarity is 1\n",
      "Topic  1 :  ['and', 'of', 'the', 'to', 'for', 'in', 'knowledge', 'alzheimeraposs', 'methods', 'a']\n",
      "Doc 0 and Topic 1 cosine similarity is 1\n",
      "Doc 1 and Topic 1 cosine similarity is 1\n",
      "Doc 2 and Topic 1 cosine similarity is 1\n",
      "Doc 3 and Topic 1 cosine similarity is 1\n",
      "Doc 4 and Topic 1 cosine similarity is 1\n",
      "Doc 5 and Topic 1 cosine similarity is 1\n",
      "Doc 6 and Topic 1 cosine similarity is 1\n",
      "Doc 7 and Topic 1 cosine similarity is 1\n",
      "Doc 8 and Topic 1 cosine similarity is 1\n",
      "Doc 9 and Topic 1 cosine similarity is 1\n",
      "Topic  2 :  ['the', 'and', 'of', 'to', 'in', 'their', 'with', 'men', 'auditory', 'are']\n",
      "Doc 0 and Topic 2 cosine similarity is 1\n",
      "Doc 1 and Topic 2 cosine similarity is 1\n",
      "Doc 2 and Topic 2 cosine similarity is 1\n",
      "Doc 3 and Topic 2 cosine similarity is 1\n",
      "Doc 4 and Topic 2 cosine similarity is 1\n",
      "Doc 5 and Topic 2 cosine similarity is 1\n",
      "Doc 6 and Topic 2 cosine similarity is 1\n",
      "Doc 7 and Topic 2 cosine similarity is 1\n",
      "Doc 8 and Topic 2 cosine similarity is 1\n",
      "Doc 9 and Topic 2 cosine similarity is 1\n",
      "Topic  3 :  ['the', 'in', 'and', 'of', 'home', 'for', 'with', 'residential', 'age', 'men']\n",
      "Doc 0 and Topic 3 cosine similarity is 1\n",
      "Doc 1 and Topic 3 cosine similarity is 1\n",
      "Doc 2 and Topic 3 cosine similarity is 1\n",
      "Doc 3 and Topic 3 cosine similarity is 1\n",
      "Doc 4 and Topic 3 cosine similarity is 1\n",
      "Doc 5 and Topic 3 cosine similarity is 1\n",
      "Doc 6 and Topic 3 cosine similarity is 1\n",
      "Doc 7 and Topic 3 cosine similarity is 1\n",
      "Doc 8 and Topic 3 cosine similarity is 1\n",
      "Doc 9 and Topic 3 cosine similarity is 1\n",
      "Topic  4 :  ['of', 'the', 'and', 'in', 'to', 'auditory', 'men', 'were', 'women', 'with']\n",
      "Doc 0 and Topic 4 cosine similarity is 1\n",
      "Doc 1 and Topic 4 cosine similarity is 1\n",
      "Doc 2 and Topic 4 cosine similarity is 1\n",
      "Doc 3 and Topic 4 cosine similarity is 1\n",
      "Doc 4 and Topic 4 cosine similarity is 1\n",
      "Doc 5 and Topic 4 cosine similarity is 1\n",
      "Doc 6 and Topic 4 cosine similarity is 1\n",
      "Doc 7 and Topic 4 cosine similarity is 1\n",
      "Doc 8 and Topic 4 cosine similarity is 1\n",
      "Doc 9 and Topic 4 cosine similarity is 1\n",
      "Topic  5 :  ['and', 'the', 'of', 'in', 'to', 'a', 'were', 'for', 'with', 'on']\n",
      "Doc 0 and Topic 5 cosine similarity is 1\n",
      "Doc 1 and Topic 5 cosine similarity is 1\n",
      "Doc 2 and Topic 5 cosine similarity is 1\n",
      "Doc 3 and Topic 5 cosine similarity is 1\n",
      "Doc 4 and Topic 5 cosine similarity is 1\n",
      "Doc 5 and Topic 5 cosine similarity is 1\n",
      "Doc 6 and Topic 5 cosine similarity is 1\n",
      "Doc 7 and Topic 5 cosine similarity is 1\n",
      "Doc 8 and Topic 5 cosine similarity is 1\n",
      "Doc 9 and Topic 5 cosine similarity is 1\n",
      "Topic  6 :  ['of', 'the', 'and', 'to', 'these', 'in', 'strategies', 'with', 'their', 'structural']\n",
      "Doc 0 and Topic 6 cosine similarity is 1\n",
      "Doc 1 and Topic 6 cosine similarity is 1\n",
      "Doc 2 and Topic 6 cosine similarity is 1\n",
      "Doc 3 and Topic 6 cosine similarity is 1\n",
      "Doc 4 and Topic 6 cosine similarity is 1\n",
      "Doc 5 and Topic 6 cosine similarity is 1\n",
      "Doc 6 and Topic 6 cosine similarity is 1\n",
      "Doc 7 and Topic 6 cosine similarity is 1\n",
      "Doc 8 and Topic 6 cosine similarity is 1\n",
      "Doc 9 and Topic 6 cosine similarity is 1\n",
      "Topic  7 :  ['the', 'in', 'and', 'of', 'elderly', 'for', 'age', 'were', 'a', 'home']\n",
      "Doc 0 and Topic 7 cosine similarity is 1\n",
      "Doc 1 and Topic 7 cosine similarity is 1\n",
      "Doc 2 and Topic 7 cosine similarity is 1\n",
      "Doc 3 and Topic 7 cosine similarity is 1\n",
      "Doc 4 and Topic 7 cosine similarity is 1\n",
      "Doc 5 and Topic 7 cosine similarity is 1\n",
      "Doc 6 and Topic 7 cosine similarity is 1\n",
      "Doc 7 and Topic 7 cosine similarity is 1\n",
      "Doc 8 and Topic 7 cosine similarity is 1\n",
      "Doc 9 and Topic 7 cosine similarity is 1\n",
      "Topic  8 :  ['the', 'and', 'of', 'in', 'to', 'a', 'men', 'with', 'institutionalization', 'women']\n",
      "Doc 0 and Topic 8 cosine similarity is 1\n",
      "Doc 1 and Topic 8 cosine similarity is 1\n",
      "Doc 2 and Topic 8 cosine similarity is 1\n",
      "Doc 3 and Topic 8 cosine similarity is 1\n",
      "Doc 4 and Topic 8 cosine similarity is 1\n",
      "Doc 5 and Topic 8 cosine similarity is 1\n",
      "Doc 6 and Topic 8 cosine similarity is 1\n",
      "Doc 7 and Topic 8 cosine similarity is 1\n",
      "Doc 8 and Topic 8 cosine similarity is 1\n",
      "Doc 9 and Topic 8 cosine similarity is 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, nb-1):\n",
    "  value=lda.get_topic_terms(i)\n",
    "  topic_words = [id2word[idx] for idx, _ in value]\n",
    "  print(\"Topic \", i, \": \", topic_words)\n",
    "  \n",
    "  #Compute cosine similarity between topic words and each document\n",
    "  for doc in texts:\n",
    "    vec1 = id2word.doc2bow(doc)\n",
    "    vec2 = id2word.doc2bow(topic_words)\n",
    "    \n",
    "    #Compute cosine similarity\n",
    "    dot_product = 0\n",
    "    doc_norm = 0\n",
    "    topic_norm = 0\n",
    "    # print(vec1)\n",
    "    # print(vec2)\n",
    "    for word_id, freq in vec1:\n",
    "        # print(vec2[word_id])\n",
    "        try:\n",
    "            dot_product += freq * vec2[word_id]\n",
    "            doc_norm += freq ** 2\n",
    "        except:\n",
    "           continue\n",
    "    for word_id, freq in vec2:\n",
    "        topic_norm += freq ** 2\n",
    "    cosine_sim = dot_product / (doc_norm ** 0.5 * topic_norm ** 0.5) if  (doc_norm ** 0.5 * topic_norm ** 0.5) > 0 else 1\n",
    "    \n",
    "    print(\"Doc {} and Topic {} cosine similarity is {}\".format(texts.index(doc), i, cosine_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('5', 0.4), ('2', 0.2), ('8', 0.2), ('7', 0.1), ('9', 0.1)]\n"
     ]
    }
   ],
   "source": [
    "topic_counts = {}\n",
    "sums = 0\n",
    "for doc_topic in doc_topics:\n",
    "    for item in doc_topic: \n",
    "        topic, prob = item\n",
    "        if topic_counts.__contains__(str(topic)):\n",
    "            topic_counts[str(topic)] = topic_counts[str(topic)]+1\n",
    "        else:\n",
    "            topic_counts[str(topic)] = 1\n",
    "        sums += 1\n",
    "\n",
    "rounds = [(topic, round(topic_count/sums, 4)) for (topic, topic_count) in topic_counts.items()]\n",
    "print(rounds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TokenVieuxM.txt\n",
    "\n",
    "As a result of taking into account the proportion of topics in documents, in one of the program's runs it was found that out of a total of 8 topics:\n",
    "\n",
    "Typical Document for each topic, topic proportion (or probability) in documents \n",
    "Topic 0: Document 0 with prob: 0.9937055706977844\n",
    "\n",
    "Topic 5: Document 1 with prob: 0.9942291975021362\n",
    "\n",
    "Topic 1: Document 2 with prob: 0.9933327436447144\n",
    "\n",
    "Topic 3: Document 3 with prob: 0.7552105784416199   \n",
    "\n",
    "Topic 4: Document 3 with prob: 0.2414269596338272\n",
    "\n",
    "Topic 8: Document 4 with prob: 0.9957541227340698\n",
    "\n",
    "In the case of measuring cosine similarity, it was found that for each document the cosine similarity was 1 with all topics. Therefore, any document can be chosen to represent any of the topics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TokenVieuxN.txt\n",
    "\n",
    "As a result of taking into account the proportion of topics in documents, in one of the program's runs it was found that out of a total of 9 topics:\n",
    "\n",
    "Topic 5: 1 :  \n",
    "with prob: 0.994229793548584\n",
    "\n",
    "Topic 2: 3 :  \n",
    "with prob: 0.9962176084518433\n",
    "\n",
    "Topic 8: 5 :  \n",
    "with prob: 0.9965642094612122\n",
    "\n",
    "Topic 7: 6 :  \n",
    "with prob: 0.9959448575973511\n",
    "\n",
    "Topic 9: 8 :  \n",
    "with prob: 0.9937487244606018\n",
    "\n",
    "In the case of measuring cosine similarity, it was found that for each document the cosine similarity was 1 with all topics. Therefore, any document can be chosen to represent any of the topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
